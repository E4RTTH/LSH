{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implementing LSH.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE6knV1DqdoA"
      },
      "source": [
        "# **Implement LSH**\r\n",
        "\r\n",
        "## Group members : \r\n",
        "#### 1. Mintra Sojiphan 6220422057 DS6\r\n",
        "#### 2. Kavin Singhakhet 6310422040 DS7\r\n",
        "#### 3.\r\n",
        "\r\n",
        "### **We implement LSH using two packages with two differnt datasets**\r\n",
        "#### 1. Package: SnaPy // Datasets: A Corpus of Plagiarised Short Answers \r\n",
        "####    References: https://github.com/justinnbt/SnaPy \r\n",
        "####                https://ir.shef.ac.uk/cloughie/resources/plagiarism_corpus.html\r\n",
        "\r\n",
        "#### 2. Package: datasketch // Dataset: News headlines\r\n",
        "####    References: https://www.learndatasci.com/tutorials/building-recommendation-engine-locality-sensitive-hashing-lsh-python/\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqZ3KXrisElc"
      },
      "source": [
        "### **1. Package: SnaPy // Datasets: A Corpus of Plagiarised Short Answers**\r\n",
        "### We will implement LSH on plagiarised answers of five different questions namely question A, B, C, D, and E to identify near duplicate answers of each question using Jaccard similarity threshold (s) = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qifqa1-s41y"
      },
      "source": [
        "\r\n",
        "\r\n",
        "### Step 1: Install and import packages\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKLz6n47JiRx"
      },
      "source": [
        "pip install snapy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msjYZ6R1JpqB"
      },
      "source": [
        "pip install mmh3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKO5pjSRKHUk"
      },
      "source": [
        "from snapy import MinHash, LSH\r\n",
        "from google.colab import drive\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import networkx as nx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7IizXuTgmxt"
      },
      "source": [
        "###Step 2: Connect Google Colab with Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzsiU2UvmO9q"
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSyAY2SHtnYa"
      },
      "source": [
        "### Step 3: Create function to perform LSH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mtu1LxpTrs_4"
      },
      "source": [
        " def LSH_task(task):\r\n",
        "\r\n",
        "  #import data \r\n",
        "  files=[]\r\n",
        "  x='/content/drive/MyDrive/corpus/'+task+'.txt'\r\n",
        "  files.append(x)\r\n",
        "  for i in range(1,20):\r\n",
        "    z='/content/drive/MyDrive/corpus/'+task+ ' ('+str(i)+').txt'\r\n",
        "    files.append(z)\r\n",
        "\r\n",
        "  docs=[]\r\n",
        "  for file in files:\r\n",
        "    file = open(file)\r\n",
        "    text = file.read()\r\n",
        "    docs.append(text)\r\n",
        "  file.close()\r\n",
        "\r\n",
        "  print(docs)\r\n",
        "  print()\r\n",
        "  print('#task: ',len(docs))\r\n",
        "  labels=[]\r\n",
        "  labels.append(task)\r\n",
        "  for i in range(1,20):\r\n",
        "    a=task+'('+str(i)+')'\r\n",
        "    labels.append(a)\r\n",
        "\r\n",
        "  seed =3\r\n",
        "\r\n",
        "  #Create MinHash object.\r\n",
        "  minhash = MinHash(docs, n_gram=9, permutations=100, hash_bits=64, seed=3)\r\n",
        "  print('Signatures metric: ',len(minhash.signatures),'x',len(minhash.signatures[0]))\r\n",
        "  print('#permutations used to create signatures:',minhash.permutations)\r\n",
        "  #print('Minhash Signatures for each text:')\r\n",
        "  #for i in minhash.signatures:\r\n",
        "    #print(i)\r\n",
        "  \r\n",
        "  # Create LSH model.\r\n",
        "  lsh = LSH(minhash, labels, no_of_bands=50)\r\n",
        "\r\n",
        "  # Query to find near duplicates for each doc.\r\n",
        "  print()\r\n",
        "  for i in labels:\r\n",
        "    print('Near duplicate for answer',i,':',lsh.query(i, min_jaccard=0.1))\r\n",
        "\r\n",
        "  # Check contents of documents.\r\n",
        "  print(lsh.contains())\r\n",
        "\r\n",
        "  # Return adjacency list for all similar texts.\r\n",
        "  adjacency_list = lsh.adjacency_list(min_jaccard=0.1)\r\n",
        "  print()\r\n",
        "  print('adjacency_lists: ',adjacency_list)\r\n",
        "  print()\r\n",
        "  # Returns edge list for use creating a weighted graph.\r\n",
        "  edge_list = lsh.edge_list(min_jaccard=0.1, jaccard_weighted=True)\r\n",
        "  print('edge lists: ',edge_list)\r\n",
        "  print()\r\n",
        "\r\n",
        "  # Create Undirected weighted graph.\r\n",
        "  fig=plt.figure(figsize =(12, 7))\r\n",
        "  fig.set_facecolor(\"#181818\")\r\n",
        "  title=\"Near duplicate answer of question \"+task\r\n",
        "  fig.suptitle(title,color= '#cccccc',fontsize=25)\r\n",
        "  G = nx.Graph()\r\n",
        "  for i in edge_list:\r\n",
        "    G.add_edge(i[0],i[1],weight=i[2])\r\n",
        "  e1=[(u,v) for (u,v,d) in G.edges(data=True) if d['weight'] > 0.5]\r\n",
        "  e2=[(u,v) for (u,v,d) in G.edges(data=True) if d['weight'] <= 0.5]\r\n",
        "  pos=nx.spring_layout(G) \r\n",
        "\r\n",
        "  # nodes\r\n",
        "  nx.draw_networkx_nodes(G,pos,node_size=1300,node_color='yellow')\r\n",
        "\r\n",
        "  # edges\r\n",
        "  edge1=nx.draw_networkx_edges(G,pos,edgelist=e1,width=4,edge_color='red')\r\n",
        "  edge2=nx.draw_networkx_edges(G,pos,edgelist=e2,width=1,edge_color='red',style='dashed')\r\n",
        "\r\n",
        "  # labels\r\n",
        "  nx.draw_networkx_labels(G,pos,font_family='sans-serif',font_size=12,font_color='#000000',font_weight=100)\r\n",
        "  keys=[(i[0],i[1]) for i in edge_list]\r\n",
        "  values= [(i[2]) for i in edge_list]\r\n",
        "  edge_labels = dict(zip(keys, values))\r\n",
        "  nx.draw_networkx_edge_labels(G,pos,edge_labels= edge_labels,font_color='red')                          \r\n",
        "  fig.set_facecolor(\"#181818\")\r\n",
        "  plt.axis('off')\r\n",
        "  fig.legend((edge1, edge2), ('sim(i,j) > 0.5', 'sim(i,j) <= 0.5'),loc=1,fontsize=15)\r\n",
        "  plt.savefig(\"LSH_graph.png\")\r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhBsAm0Kt41S"
      },
      "source": [
        "### Step 4: Perform LSH on set of 20 plagiarised answers of the following questions to identify near duplicate answers using Jaccard similarity threshold (s) = 0.5\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv0HW-eu0vWx"
      },
      "source": [
        "#### **Question A**: The result illustrates that there are 3 pairs of answers which can be identified as near duplicate answers as shown below:\r\n",
        "#### 1. Answer A(1) and A(18) with Jaccard similarity of 0.9\r\n",
        "#### 2. Answer A(1) and A(6) with Jaccard similarity of 0.74\r\n",
        "#### 3. Answer A(6) and A(18) with Jaccard similarity of 0.7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30KOIz6983Pi"
      },
      "source": [
        "LSH_task('A')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwOasyoY06B_"
      },
      "source": [
        "#### **Question B**: The result illustrates that there are no pairs of answers which can be identified as near duplicate answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvSjMo3NVCSu"
      },
      "source": [
        "LSH_task('B')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSz3BjVQ6s8T"
      },
      "source": [
        "#### **Question C**: The result illustrates that there are no pairs of answers which can be identified as near duplicate answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtwFSq90VeLl"
      },
      "source": [
        "LSH_task('C')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAX0f25c_BcK"
      },
      "source": [
        "#### **Question D**:The result illustrates that there are 3 pairs of answers which can be identified as near duplicate answers as shown below:\r\n",
        "#### 1. Answer D and D(14) with Jaccard similarity of 0.7\r\n",
        "#### 2. Answer D and D(18) with Jaccard similarity of 0.68\r\n",
        "#### 3. Answer D(18) and A(14) with Jaccard similarity of 0.62"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfHlVfV7VlRg"
      },
      "source": [
        "LSH_task('D')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLK2m4Ey_frl"
      },
      "source": [
        "#### **Question E**: The result illustrates that there are no pairs of answers which can be identified as near duplicate answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEZyhKbsVo1d"
      },
      "source": [
        "LSH_task('E')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PtMM2ki5Kqq"
      },
      "source": [
        "### **2. Package: datasketch // Dataset: News headlines**\r\n",
        "### We will implement LSH to create news headlines recommendation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw9MSnHQ5U2L"
      },
      "source": [
        "### Step 1: Install and Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmMP2w5mAGaL",
        "outputId": "a5aba940-5593-4cf7-85b7-8745a7eb4621"
      },
      "source": [
        "pip install datasketch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasketch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/35/3e39356d97dc67c4bddaddb51693c20a6eb61e535ce5be09d3755ba2b823/datasketch-1.5.3-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 40kB 10.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from datasketch) (1.19.5)\n",
            "Installing collected packages: datasketch\n",
            "Successfully installed datasketch-1.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1NBfGIi54Bf"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "import time\r\n",
        "from datasketch import MinHash, MinHashLSHForest"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iL3Xbpr6Kf0"
      },
      "source": [
        "### Step 2: Acquire data using web scraping package (BeautifulSoup)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWzQ0SIIUbDS"
      },
      "source": [
        "from bs4 import BeautifulSoup\r\n",
        "import requests\r\n",
        "\r\n",
        "url1 = 'https://www.reuters.com/news/archive/technologynews?view=page&page=1&pageSize=10'\r\n",
        "url2 = 'https://www.reuters.com/news/archive/technologynews?view=page&page=2&pageSize=10'\r\n",
        "url3 = 'https://www.reuters.com/news/archive/technologynews?view=page&page=3&pageSize=10'\r\n",
        "url4 = 'https://www.reuters.com/news/archive/technologynews?view=page&page=4&pageSize=10'\r\n",
        "url5 = 'https://www.reuters.com/news/archive/technologynews?view=page&page=5&pageSize=10'\r\n",
        "\r\n",
        "def web_scraping_news(url):\r\n",
        "    r = requests.get(url)\r\n",
        "    html = r.text\r\n",
        "    soup = BeautifulSoup(html,'lxml')\r\n",
        "    div_tag = soup.find_all('h3',attrs={'class':\"story-title\"})\r\n",
        "    news = [i for i in div_tag]\r\n",
        "\r\n",
        "    return news"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjaXfvJn5wb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfe3ca04-dee2-433b-ba84-e95f794d3f87"
      },
      "source": [
        "news1 = web_scraping_news(url1)\r\n",
        "news2 = web_scraping_news(url2)\r\n",
        "news3 = web_scraping_news(url3)\r\n",
        "news4 = web_scraping_news(url4)\r\n",
        "news5 = web_scraping_news(url5)\r\n",
        "news = news1 + news2 + news3 + news4 + news5\r\n",
        "titles = [str(i) for i in news]\r\n",
        "\r\n",
        "#Extract News Headline\r\n",
        "headlines = [a.strip(''''<h3 class=\"story-title\">\r\n",
        "\t\t\t\t\t\t\t\t''').rstrip('</') for a in titles]\r\n",
        "\r\n",
        "for headline in headlines:\r\n",
        "    print(headline)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elon Musk, back on Twitter, turns his support to Dogecoin\n",
            "Mazda expects chip shortage to affect about 7,000 vehicles in February\n",
            "Retail frenzy stalls as focus falls on regulator meeting\n",
            "GameStop rises, AMC dips in early U.S. premarket trading\n",
            "Uber's Mideast business Careem sees recovery slowing as infections rise\n",
            "Australian drone firm reshapes strategy over Google pull-out threat\n",
            "NatWest latest UK bank to switch to Mastercard debit cards from Visa\n",
            "Ethereum scales record peak before futures launch\n",
            "Five things to watch in Reddit stocks trading mania\n",
            "Taiwan says auto chip shortage not a main topic for coming U.S. meeting\n",
            "In uneasy truce, House Republicans fail to punish Greene or Cheney\n",
            "Biden to pursue arms control, seeks to engage China, U.S. envoy says\n",
            "U.S. charges Seattle-based Proud Boys member for role in Capitol riots\n",
            "Nokia fourth-quarter profit, revenue beat as CEO Lundmark revamps strategy\n",
            "Parler CEO John Matze says he was fired by board\n",
            "Reddit rally' stocks bounce on day after selloff, then dip after hours\n",
            "U.S. Treasury's Yellen to meet financial regulators Thursday to discuss  volatility\n",
            "Robinhood to allow buying fractional shares of GameStop, AMC\n",
            "Alibaba sets initial price guidance on $5 billion bond offering: term sheet\n",
            "Two Google engineers resign over firing of AI ethics researcher Timnit Gebru\n",
            "Amazon plans AI-powered cameras in delivery vans to improve driver safety\n",
            "Qualcomm shares drop as chip supply constraints hold back sales\n",
            "Ebay earnings beat on pandemic-driven surge in online shopping; shares soar\n",
            "Pentagon, stumped by extremism in ranks, orders stand-down in next 60 days\n",
            "Biden decides to stick with Space Force as branch of U.S. military\n",
            "Top House Republican mentions no action to reprimand Greene in statement on controversial lawmaker\n",
            "PayPal profit tops estimates as pandemic drives online spending to record levels\n",
            "SEC studies social media posts for signs of fraud in GameStop frenzy: Bloomberg\n",
            "Number of GameStop shares shorted edges higher: S3 Partners\n",
            "Spotify outlook weakens as pandemic uncertainty persists\n",
            "Ant Group reaches deal with China regulators on restructuring - source\n",
            "Daimler to spin off truck unit, sharpen investor focus on Mercedes-Benz\n",
            "Amazon unveils development plans for next phase of Virginia headquarters\n",
            "GM hit by chip shortage, to cut production at four plants\n",
            "Five things to watch in Reddit stocks trading mania\n",
            "GameStop, AMC shares reverse course in retail trading rollercoaster\n",
            "Schumer, after Biden meeting, says Democrats united on a 'bold' COVID-19 bill\n",
            "Biden tells congressional Democrats would consider limits on who gets COVID-19 checks\n",
            "Trump impeachment lawyer says would be 'idiotic,' 'insane' to rehash election fraud claims\n",
            "Game on after GameStop: Stocks soar again despite amber warnings\n",
            "Retail trading fever drives U.S. equity option volumes to record monthly high\n",
            "Germany predicts chip investments of up to 50 billion euros in Europe\n",
            "TikTok agrees to block users in Italy who say they are under 13 after girl dies\n",
            "Chip crunch to impact global auto production into third quarter, says IHS\n",
            "Bezos to give Amazon reins to cloud boss Jassy as sales rocket past $100 billion\n",
            "Bezos' shock exit cools Amazon results boost\n",
            "Sony raises outlook amid home entertainment boom, but struggles to build more PS5s\n",
            "Microsoft backs Australia's proposed media laws, eyes expansion\n",
            "Tiktok strengthens content review with new pre-share prompts\n",
            "U.S. Democrats take first step to go it alone on Biden's COVID-19 aid\n",
            "Factbox: What has Biden done so far to roll back Trump's immigration policies?\n",
            "U.S. Senate confirms Mayorkas as homeland security secretary over Republican opposition\n",
            "China's Lenovo posts record profit in third-quarter, beating expectations\n",
            "Cryptocurrency Ethereum hits record high ahead of CME futures launch\n",
            "Mazda may cut global vehicle output by 34,000 in February and March, sources say\n",
            "Japan's COVID-19 app failed to pass on some contact warnings\n",
            "South Korea carmaker Kia's shares jump 14.5% on Apple EV tie-up report\n",
            "Elon Musk's banter with Robinhood CEO triggers stampede for Clubhouse app\n",
            "SpaceX Starship prototype rocket explodes on landing after test launch\n",
            "Sweden's Embracer expands reach with $2.5 billion game buying spree\n",
            "Exclusive: Suspected Chinese hackers used SolarWinds bug to spy on U.S. payroll agency – sources\n",
            "Indian trade secretary stands by digital tax opposed by U.S.\n",
            "Pentagon purges advisory boards after flurry of Trump end-of-term appointees\n",
            "White House says it needs time to put in place a 'moral', 'humane' immigration process\n",
            "Trump uses impeachment response to vent about election defeat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPPdf4M06ays"
      },
      "source": [
        "### Step 3: Create functions to perform news headlines recommendations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qKKgr_M5yyK"
      },
      "source": [
        "def preprocess(text, char_ngram=5):\r\n",
        "    \r\n",
        "    return set(text[head:head + char_ngram] for head in range(0, len(text) - char_ngram))\r\n",
        "\r\n",
        "def get_forest(data, perms):\r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    minhash = []\r\n",
        "    \r\n",
        "    for text in data['title']:\r\n",
        "        tokens = preprocess(text)\r\n",
        "        m = MinHash(num_perm=perms)\r\n",
        "        for s in tokens:\r\n",
        "            m.update(s.encode('utf8'))\r\n",
        "        minhash.append(m)\r\n",
        "        \r\n",
        "    forest = MinHashLSHForest(num_perm=perms)\r\n",
        "    \r\n",
        "    for i,m in enumerate(minhash):\r\n",
        "        forest.add(i,m)\r\n",
        "        \r\n",
        "    forest.index()\r\n",
        "    \r\n",
        "    print('It took %s seconds to build forest.' %(time.time()-start_time))\r\n",
        "    \r\n",
        "    return forest\r\n",
        "\r\n",
        "def predict(text, data, perms, num_results, forest):\r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    tokens = preprocess(text)\r\n",
        "    m = MinHash(num_perm=perms)\r\n",
        "    for s in tokens:\r\n",
        "        m.update(s.encode('utf8'))\r\n",
        "        \r\n",
        "    idx_array = np.array(forest.query(m, num_results))\r\n",
        "    if len(idx_array) == 0:\r\n",
        "        return None # if your query is empty, return none\r\n",
        "    \r\n",
        "    result = data.iloc[idx_array]['title']\r\n",
        "    \r\n",
        "    print('It took %s seconds to query forest.' %(time.time()-start_time))\r\n",
        "    \r\n",
        "    return result"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "7giyGFu159QT",
        "outputId": "9932948a-2d26-4b04-d153-bb271f2ab9b7"
      },
      "source": [
        "data = pd.DataFrame(headlines,columns= ['title'])\r\n",
        "data.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Elon Musk, back on Twitter, turns his support ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mazda expects chip shortage to affect about 7,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Retail frenzy stalls as focus falls on regulat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GameStop rises, AMC dips in early U.S. premark...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Uber's Mideast business Careem sees recovery s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title\n",
              "0  Elon Musk, back on Twitter, turns his support ...\n",
              "1  Mazda expects chip shortage to affect about 7,...\n",
              "2  Retail frenzy stalls as focus falls on regulat...\n",
              "3  GameStop rises, AMC dips in early U.S. premark...\n",
              "4  Uber's Mideast business Careem sees recovery s..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us8P0VAp5_Nu",
        "outputId": "269e6cc5-d652-4158-b071-5d3f18dc4ae1"
      },
      "source": [
        "forest = get_forest(data, 100)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It took 0.13052773475646973 seconds to build forest.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BnveRx2NNDw"
      },
      "source": [
        "### Step 4: Predict news headlines recommendations for the given title.\r\n",
        "### \"xxxxxxxxxxxxxxxxxxxxxxxx\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VddfRReR6BCp",
        "outputId": "93b68a7b-4b72-4bd7-e194-e076dd822232"
      },
      "source": [
        "title = \"Stocks explained: What's going on with GameStop?\"\r\n",
        "result = predict(title, data, 100, 10, forest)\r\n",
        "print('\\n Top Recommendation(s) is(are) \\n', result)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It took 0.004659414291381836 seconds to query forest.\n",
            "\n",
            " Top Recommendation(s) is(are) \n",
            " 48    Tiktok strengthens content review with new pre...\n",
            "57    Elon Musk's banter with Robinhood CEO triggers...\n",
            "59    Sweden's Embracer expands reach with $2.5 bill...\n",
            "39    Game on after GameStop: Stocks soar again desp...\n",
            "Name: title, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}